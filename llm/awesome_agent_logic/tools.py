"""
AwesomeAgenté€»è¾‘: å·¥å…·é›†

è¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†AwesomeAgentLogicå¯ä»¥ä½¿ç”¨çš„å„ç§å·¥å…·ã€‚è¿™äº›å·¥å…·è¢«è®¾è®¡ä¸ºå¯ä»¥ç”±å¤§æ¨¡å‹è°ƒç”¨çš„å‡½æ•°ï¼Œ
æ¯ä¸ªå·¥å…·éƒ½æœ‰æ˜ç¡®çš„è¾“å…¥å’Œè¾“å‡ºï¼Œä»¥åŠè¯¦ç»†çš„æ–‡æ¡£è¯´æ˜ã€‚
"""

import logging
import requests
import re
import math
import json
import time
from datetime import datetime
from bs4 import BeautifulSoup
from typing import List, Dict, Any, Optional, Union, Tuple

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

class GithubTools:
    """GitHubç›¸å…³å·¥å…·é›†"""
    
    @staticmethod
    def search_github_repositories(keywords: List[str], access_token: str, limit: int = 10) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨å…³é”®è¯æœç´¢GitHubä»“åº“

        Args:
            keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            access_token: GitHub APIè®¿é—®ä»¤ç‰Œ
            limit: æ¯ä¸ªå…³é”®è¯è¿”å›çš„æœ€å¤§ç»“æœæ•°é‡

        Returns:
            List[Dict]: åŒ…å«ä»“åº“ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        """
        logger.info(f"æœç´¢GitHubä»“åº“ï¼Œå…³é”®è¯: {keywords}")
        
        all_repos = []
        headers = {
            'Authorization': f'token {access_token}',
            'Accept': 'application/vnd.github+json',
            'X-GitHub-Api-Version': '2022-11-28'
        }
        
        for keyword in keywords:
            try:
                # æ„å»ºæœç´¢æŸ¥è¯¢ï¼ŒæŒ‰æ˜Ÿæ•°æ’åº
                query = f"{keyword} sort:stars"
                url = f"https://api.github.com/search/repositories?q={query}&per_page={limit}"
                
                response = requests.get(url, headers=headers)
                response.raise_for_status()
                
                repos = response.json().get('items', [])
                all_repos.extend(repos)
                
                logger.info(f"å…³é”®è¯ '{keyword}' è¿”å› {len(repos)} ä¸ªç»“æœ")
                
                # é¿å…è§¦å‘GitHub APIé™é€Ÿ
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"æœç´¢å…³é”®è¯ '{keyword}' å¤±è´¥: {e}")
        
        return all_repos
    
    @staticmethod
    def get_repo_details(repo_url: str, access_token: str) -> Dict[str, Any]:
        """
        è·å–GitHubä»“åº“çš„è¯¦ç»†ä¿¡æ¯

        Args:
            repo_url: GitHubä»“åº“URL
            access_token: GitHub APIè®¿é—®ä»¤ç‰Œ

        Returns:
            Dict: åŒ…å«ä»“åº“è¯¦ç»†ä¿¡æ¯çš„å­—å…¸
        """
        logger.info(f"è·å–ä»“åº“è¯¦æƒ…: {repo_url}")
        
        try:
            # ä»URLæå–ç”¨æˆ·åå’Œä»“åº“å
            match = re.search(r'github.com/([^/]+)/([^/]+)', repo_url)
            if not match:
                logger.error(f"æ— æ³•ä»URLè§£æä»“åº“ä¿¡æ¯: {repo_url}")
                return {}
            
            owner, repo = match.groups()
            
            # è¯·æ±‚ä»“åº“è¯¦æƒ…
            api_url = f"https://api.github.com/repos/{owner}/{repo}"
            headers = {
                'Authorization': f'token {access_token}',
                'Accept': 'application/vnd.github+json',
                'X-GitHub-Api-Version': '2022-11-28'
            }
            
            response = requests.get(api_url, headers=headers)
            response.raise_for_status()
            
            data = response.json()
            return {
                'url': data['html_url'],
                'name': data['name'],
                'full_name': data['full_name'],
                'description': data.get('description', ''),
                'stars': data['stargazers_count'],
                'forks': data['forks_count'],
                'pushed_at': data['pushed_at'],
                'created_at': data['created_at'],
                'updated_at': data['updated_at'],
                'language': data.get('language')
            }
            
        except Exception as e:
            logger.error(f"è·å–ä»“åº“è¯¦æƒ…å¤±è´¥: {e}")
            return {}
    
    @staticmethod
    def calculate_repo_score(repo: Dict[str, Any]) -> float:
        """
        è®¡ç®—ä»“åº“åˆ†æ•°

        è¯„åˆ†å…¬å¼: (0.7 * log(Stars + 1) + 0.3 * log(Forks + 1)) * RecencyScore

        Args:
            repo: åŒ…å«ä»“åº“ä¿¡æ¯çš„å­—å…¸

        Returns:
            float: è®¡ç®—å¾—å‡ºçš„åˆ†æ•°
        """
        try:
            stars = repo.get('stars', 0) or repo.get('stargazers_count', 0)
            forks = repo.get('forks', 0) or repo.get('forks_count', 0)
            pushed_at = repo.get('pushed_at', '')
            
            # è®¡ç®—æ–°è¿‘åº¦åˆ†æ•°
            recency_score = 0.1  # é»˜è®¤å¾ˆä½
            if pushed_at:
                # è§£ææ—¥æœŸ
                pushed_date = datetime.strptime(pushed_at, "%Y-%m-%dT%H:%M:%SZ")
                days_diff = (datetime.utcnow() - pushed_date).days
                
                # æ ¹æ®æ›´æ–°æ—¶é—´è®¡ç®—æ–°è¿‘åº¦å¾—åˆ†
                if days_diff <= 30:  # 1ä¸ªæœˆå†…
                    recency_score = 1.0
                elif days_diff <= 180:  # 6ä¸ªæœˆå†…
                    recency_score = 0.8
                elif days_diff <= 365:  # 1å¹´å†…
                    recency_score = 0.5
                elif days_diff <= 730:  # 2å¹´å†…
                    recency_score = 0.2
                else:  # è¶…è¿‡2å¹´
                    recency_score = 0.05
            
            # è®¡ç®—ç»¼åˆåˆ†æ•°
            score = (0.7 * math.log(stars + 1) + 0.3 * math.log(forks + 1)) * recency_score
            return score
            
        except Exception as e:
            logger.error(f"è®¡ç®—ä»“åº“åˆ†æ•°å¤±è´¥: {e}")
            return 0.0


class WebTools:
    """ç½‘ç»œæœç´¢å’Œå¤„ç†å·¥å…·é›†"""
    
    @staticmethod
    def search_web(query: str, tavily_api_key: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ç½‘ç»œæœç´¢æŸ¥è¯¢ç›¸å…³å†…å®¹

        Args:
            query: æœç´¢æŸ¥è¯¢
            tavily_api_key: Tavilyæœç´¢APIå¯†é’¥(å¯é€‰)

        Returns:
            List[Dict]: æœç´¢ç»“æœåˆ—è¡¨
        """
        logger.info(f"æ‰§è¡Œç½‘ç»œæœç´¢: {query}")
        
        results = []
        
        # å¦‚æœæä¾›äº†Tavily APIå¯†é’¥ï¼Œå°è¯•ä½¿ç”¨Tavily
        if tavily_api_key:
            try:
                from tavily import TavilyClient
                client = TavilyClient(api_key=tavily_api_key)
                
                response = client.search(query=query, search_depth="basic", max_results=5)
                for result in response.get("results", []):
                    results.append({
                        "title": result.get("title", ""),
                        "url": result.get("url", ""),
                        "snippet": result.get("content", "")
                    })
                    
                if results:
                    return results
                    
            except Exception as e:
                logger.warning(f"Tavilyæœç´¢å¤±è´¥: {e}")
        
        # å›é€€åˆ°ç®€å•çš„DuckDuckGoæœç´¢
        try:
            url = f"https://api.duckduckgo.com/?q={query}&format=json"
            response = requests.get(url)
            
            if response.status_code == 200:
                data = response.json()
                
                for result in data.get("Results", []):
                    results.append({
                        "title": result.get("Text", ""),
                        "url": result.get("FirstURL", ""),
                        "snippet": ""
                    })
        except Exception as e:
            logger.error(f"DuckDuckGoæœç´¢å¤±è´¥: {e}")
        
        return results
    
    @staticmethod
    def extract_github_links(url: str) -> List[str]:
        """
        ä»ç½‘é¡µä¸­æå–GitHubä»“åº“é“¾æ¥

        Args:
            url: ç½‘é¡µURL

        Returns:
            List[str]: æå–çš„GitHubä»“åº“URLåˆ—è¡¨
        """
        logger.info(f"ä»URLæå–GitHubé“¾æ¥: {url}")
        github_urls = []
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code != 200:
                logger.warning(f"è·å–é¡µé¢å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return []
                
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…GitHubä»“åº“é“¾æ¥
            pattern = r'https?://github\.com/[a-zA-Z0-9\-]+/[a-zA-Z0-9\-\._]+'
            
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
            for link in soup.find_all('a', href=True):
                href = link['href']
                if re.match(pattern, href):
                    # è§„èŒƒåŒ–URL
                    clean_url = re.sub(r'[#?].*$', '', href).rstrip('/')
                    if clean_url not in github_urls:
                        github_urls.append(clean_url)
            
            logger.info(f"ä»URLæå–äº† {len(github_urls)} ä¸ªGitHubé“¾æ¥")
            
        except Exception as e:
            logger.error(f"æå–GitHubé“¾æ¥å¤±è´¥: {e}")
        
        return github_urls


class LLMTools:
    """å¤§è¯­è¨€æ¨¡å‹å·¥å…·é›†"""
    
    @staticmethod
    def generate_keywords(domain: str, llm) -> List[str]:
        """
        ä½¿ç”¨LLMç”Ÿæˆæœç´¢å…³é”®è¯

        Args:
            domain: ç”¨æˆ·æ„Ÿå…´è¶£çš„é¢†åŸŸ
            llm: å¤§è¯­è¨€æ¨¡å‹æ¥å£

        Returns:
            List[str]: ç”Ÿæˆçš„å…³é”®è¯åˆ—è¡¨
        """
        logger.info(f"ä½¿ç”¨LLMä¸ºé¢†åŸŸ '{domain}' ç”Ÿæˆå…³é”®è¯")
        
        try:
            from langchain_core.prompts import PromptTemplate
            from langchain_core.output_parsers import StrOutputParser
            
            prompt_template = """
            ä½œä¸ºä¸€åä¸“ä¸šçš„æœç´¢ä¼˜åŒ–ä¸“å®¶ï¼Œè¯·ä¸ºç”¨æˆ·æä¾›çš„é¢†åŸŸç”Ÿæˆ5-8ä¸ªç”¨äºåœ¨GitHubä¸Šæœç´¢é«˜è´¨é‡ä»“åº“çš„å…³é”®è¯æˆ–çŸ­è¯­ã€‚

            ç”¨æˆ·æ„Ÿå…´è¶£çš„é¢†åŸŸæ˜¯: "{domain}"

            è¯·ç¡®ä¿:
            1. ç”Ÿæˆçš„å…³é”®è¯å¿…é¡»æ˜¯è‹±æ–‡çš„ï¼Œæ— è®ºç”¨æˆ·è¾“å…¥ä»€ä¹ˆè¯­è¨€
            2. å…³é”®è¯åº”è¯¥å¤šæ ·åŒ–ï¼Œè¦†ç›–ä¸åŒçš„å­¦ä¹ èµ„æºç±»å‹(å¦‚æ•™ç¨‹ã€æŒ‡å—ã€awesomeåˆ—è¡¨ã€æœ€ä½³å®è·µç­‰)
            3. å…³é”®è¯åº”åŒ…æ‹¬é¢†åŸŸç‰¹å®šçš„æœ¯è¯­

            å¦‚æœç”¨æˆ·è¾“å…¥çš„é¢†åŸŸæ˜¯ä¸­æ–‡æˆ–å…¶ä»–éè‹±æ–‡è¯­è¨€ï¼Œè¯·å…ˆç†è§£å…¶å«ä¹‰ï¼Œç„¶åç”Ÿæˆå¯¹åº”çš„è‹±æ–‡å…³é”®è¯ã€‚

            è¯·åªè¿”å›ä¸€ä¸ªJSONæ ¼å¼çš„å…³é”®è¯æ•°ç»„ï¼Œä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæˆ–å‰å¯¼æ–‡æœ¬ã€‚
            æ ¼å¼ç¤ºä¾‹:
            ["keyword1", "keyword2", "keyword3", "keyword4", "keyword5"]
            """
            
            prompt = PromptTemplate.from_template(prompt_template)
            chain = prompt | llm | StrOutputParser()
            
            result = chain.invoke({"domain": domain})
            
            # æ¸…ç†ç»“æœ
            cleaned_result = result.strip()
            if cleaned_result.startswith("```json"):
                cleaned_result = cleaned_result.removeprefix("```json").removesuffix("```")
            elif cleaned_result.startswith("```"):
                cleaned_result = cleaned_result.removeprefix("```").removesuffix("```")
            
            # è§£æJSON
            keywords = json.loads(cleaned_result)
            if not isinstance(keywords, list):
                raise ValueError("ç”Ÿæˆçš„å…³é”®è¯ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
                
            return keywords
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆå…³é”®è¯å¤±è´¥: {e}")
            # è¿”å›åŸºç¡€å…³é”®è¯ä»¥ç¡®ä¿æµç¨‹ç»§ç»­
            return ["awesome repositories", "tutorial", "guide", "examples", "resources"]
    
    @staticmethod
    def generate_web_queries(domain: str, llm) -> List[str]:
        """
        ä½¿ç”¨LLMä¸ºç½‘ç»œæœç´¢ç”ŸæˆæŸ¥è¯¢è¯­å¥

        Args:
            domain: ç”¨æˆ·æ„Ÿå…´è¶£çš„é¢†åŸŸ
            llm: å¤§è¯­è¨€æ¨¡å‹æ¥å£

        Returns:
            List[str]: ç”Ÿæˆçš„æŸ¥è¯¢è¯­å¥åˆ—è¡¨
        """
        logger.info(f"ä½¿ç”¨LLMä¸ºé¢†åŸŸ '{domain}' ç”Ÿæˆç½‘ç»œæœç´¢æŸ¥è¯¢")
        
        try:
            from langchain_core.prompts import PromptTemplate
            from langchain_core.output_parsers import StrOutputParser
            
            prompt_template = """
            ä½œä¸ºä¸€åæœç´¢ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä¸ºå¯»æ‰¾GitHubä¸Šä¼˜è´¨ä»“åº“èµ„æºç”Ÿæˆæœ‰æ•ˆçš„ç½‘ç»œæœç´¢æŸ¥è¯¢ã€‚
            
            ç”¨æˆ·å¯¹è¿™ä¸ªé¢†åŸŸæ„Ÿå…´è¶£: "{domain}"
            
            è¯·ç”Ÿæˆ3-5ä¸ªä¸åŒçš„æœç´¢æŸ¥è¯¢ï¼Œè¿™äº›æŸ¥è¯¢å¿…é¡»æ˜¯è‹±æ–‡çš„ï¼Œæ— è®ºç”¨æˆ·è¾“å…¥çš„æ˜¯ä»€ä¹ˆè¯­è¨€ã€‚
            è¿™äº›æŸ¥è¯¢åº”è¯¥èƒ½å¸®åŠ©æ‰¾åˆ°æ¨èGitHubä»“åº“çš„é«˜è´¨é‡æ–‡ç« æˆ–èµ„æºåˆ—è¡¨ã€‚
            
            å¦‚æœç”¨æˆ·è¾“å…¥çš„é¢†åŸŸæ˜¯ä¸­æ–‡ï¼Œè¯·å…ˆç†è§£è¯¥é¢†åŸŸçš„å«ä¹‰ï¼Œç„¶åç”Ÿæˆå¯¹åº”çš„è‹±æ–‡æœç´¢æŸ¥è¯¢ã€‚
            
            æŸ¥è¯¢åº”è¯¥å¤šæ ·åŒ–ï¼Œè¦†ç›–ä¸åŒè§’åº¦ï¼Œä¾‹å¦‚ï¼š
            - å¯»æ‰¾"æœ€ä½³/é¡¶çº§/æ¨è"ä»“åº“åˆ—è¡¨
            - å¯»æ‰¾å­¦ä¹ è·¯å¾„æˆ–æ•™ç¨‹é›†åˆ
            - å¯»æ‰¾ä¸“å®¶æ¨èæˆ–ç²¾é€‰èµ„æº
            
            å¯ä»¥ä½¿ç”¨ä¸€äº›ç®€å•çš„æ¨¡æ¿ï¼Œå¦‚"best llm repositories github"ã€‚ä¹Ÿä½¿ç”¨æ›´æœ‰é’ˆå¯¹æ€§çš„æœç´¢è¯­å¥ï¼Œä½†æ˜¯è¯­å¥åº”è¯¥å°½é‡çš„çŸ­ï¼Œæœ€å¥½ä¸è¦è¶…è¿‡5ä¸ªè¯ã€‚
            è€ƒè™‘ç‰¹å®šé¢†åŸŸçš„æœ¯è¯­å’Œå¸¸è§æœç´¢æ¨¡å¼ã€‚
            
            ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªJSONæ ¼å¼çš„å­—ç¬¦ä¸²æ•°ç»„ï¼Œä»…åŒ…å«ç”Ÿæˆçš„è‹±æ–‡æŸ¥è¯¢ï¼Œä¸è¦æœ‰é¢å¤–çš„è§£é‡Šã€‚
            
            ç¤ºä¾‹è¾“å‡ºæ ¼å¼:
            ["machine learning github repositories", "top rated deep learning frameworks", "github collections for AI beginners"]
            """
            
            prompt = PromptTemplate.from_template(prompt_template)
            chain = prompt | llm | StrOutputParser()
            
            result = chain.invoke({"domain": domain})
            
            # æ¸…ç†ç»“æœ
            cleaned_result = result.strip()
            if cleaned_result.startswith("```json"):
                cleaned_result = cleaned_result.removeprefix("```json").removesuffix("```")
            elif cleaned_result.startswith("```"):
                cleaned_result = cleaned_result.removeprefix("```").removesuffix("```")
            
            # è§£æJSON
            queries = json.loads(cleaned_result)
            if not isinstance(queries, list):
                raise ValueError("ç”Ÿæˆçš„æŸ¥è¯¢ä¸æ˜¯åˆ—è¡¨æ ¼å¼")
                
            return queries
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆç½‘ç»œæœç´¢æŸ¥è¯¢å¤±è´¥: {e}")
            # è¿”å›åŸºç¡€æŸ¥è¯¢ä»¥ç¡®ä¿æµç¨‹ç»§ç»­
            return [
                f"best github repositories for {domain}",
                f"top {domain} projects on github",
                f"recommended {domain} libraries github"
            ]
    
    @staticmethod
    def generate_final_report(repos: List[Dict], domain: str, llm) -> str:
        """
        ä½¿ç”¨LLMä¸ºæ’åºåçš„ä»“åº“ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š

        Args:
            repos: æ’åºåçš„ä»“åº“ä¿¡æ¯åˆ—è¡¨
            domain: ç”¨æˆ·æ„Ÿå…´è¶£çš„é¢†åŸŸ
            llm: å¤§è¯­è¨€æ¨¡å‹æ¥å£

        Returns:
            str: Markdownæ ¼å¼çš„æœ€ç»ˆæŠ¥å‘Š
        """
        logger.info(f"ä½¿ç”¨LLMä¸º {len(repos)} ä¸ªä»“åº“ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        
        try:
            from langchain_core.prompts import PromptTemplate
            from langchain_core.output_parsers import StrOutputParser
            
            # æ ¼å¼åŒ–ä»“åº“ä¿¡æ¯
            repos_text = ""
            for i, repo in enumerate(repos[:5], 1):  # åªå–å‰5ä¸ª
                # æ ¼å¼åŒ–æ—¥æœŸ
                pushed_at = repo.get('pushed_at', '')
                if pushed_at:
                    try:
                        date = datetime.strptime(pushed_at, "%Y-%m-%dT%H:%M:%SZ")
                        pushed_at = date.strftime("%Yå¹´%mæœˆ%dæ—¥")
                    except:
                        pass
                
                repos_text += f"## ä»“åº“ {i}\n"
                repos_text += f"åç§°: {repo.get('full_name', 'Unknown')}\n"
                repos_text += f"URL: {repo.get('url', '')}\n"
                repos_text += f"æè¿°: {repo.get('description', '')}\n"
                repos_text += f"Stars: {repo.get('stars', 0)}\n"
                repos_text += f"Forks: {repo.get('forks', 0)}\n"
                repos_text += f"æœ€è¿‘æ›´æ–°: {pushed_at}\n"
                repos_text += f"ä¸»è¦è¯­è¨€: {repo.get('language', 'Unknown')}\n\n"
            
            prompt_template = """
            ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIæŠ€æœ¯åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·å‡†å¤‡ä¸€ä»½å…³äº"{domain}"é¢†åŸŸçš„é¡¶å°– GitHub å­¦ä¹ èµ„æºæŠ¥å‘Šã€‚

            æˆ‘å·²ç»ä¸ºä½ æä¾›äº†æ’åæœ€é«˜çš„ {top_n} ä¸ªä»“åº“çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåç§°ã€URLã€æè¿°ã€Staræ•°ã€Forkæ•°ã€æœ€è¿‘æ›´æ–°æ—¶é—´ï¼‰ã€‚

            **ä»“åº“ä¿¡æ¯**:
            {ranked_top_n_repos_details}

            è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ç²¾ç‚¼ã€æ˜“è¯»çš„ Markdown æ ¼å¼æŠ¥å‘Šï¼Œè¦ä¸¥æ ¼ç¬¦åˆmarkdownçš„è¯­æ³•ã€‚æŠ¥å‘Šåº”åŒ…å«ä»¥ä¸‹è¦ç´ ï¼š

            1.  ä¸€ä¸ªå¼•äººæ³¨ç›®çš„æ ‡é¢˜ï¼Œç‚¹æ˜æŠ¥å‘Šä¸»é¢˜ï¼ˆä¾‹å¦‚ï¼š" Top 5 GitHub å®è—é¡¹ç›®æ¨èï¼‰ã€‚
            2.  ä¸€æ®µç®€çŸ­çš„å¼•è¨€ï¼Œè¯´æ˜è¿™ä»½æŠ¥å‘Šæ˜¯å¦‚ä½•é€šè¿‡å¤šç»´åº¦è¯„ä¼°å¾—å‡ºçš„ï¼Œå¼ºè°ƒå…¶å®¢è§‚æ€§å’Œæ—¶æ•ˆæ€§ã€‚
            3.  å¯¹æ¯ä¸€ä¸ªæ¨èä»“åº“çš„ç‹¬ç«‹ä»‹ç»ï¼ŒåŒ…æ‹¬ï¼š
                - **é¡¹ç›®åç§°å’Œé“¾æ¥**: ä½œä¸ºäºŒçº§æˆ–ä¸‰çº§æ ‡é¢˜ã€‚
                - **æ ¸å¿ƒæŒ‡æ ‡**: `Stars`, `Forks`, `æœ€è¿‘æ›´æ–°`ã€‚
                - **ä¸€å¥è¯æ€»ç»“**: ç²¾å‡†æ¦‚æ‹¬è¿™ä¸ªé¡¹ç›®æ˜¯ä»€ä¹ˆã€‚
                - **æ¨èç†ç”±**: è¯¦ç»†è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªé¡¹ç›®å€¼å¾—å…³æ³¨ã€‚å®ƒè§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿæ˜¯æ•™ç¨‹ã€å·¥å…·è¿˜æ˜¯èµ„æºåº“ï¼Ÿï¼ˆä¾‹å¦‚ï¼š"è¿™æ˜¯ä¸€ä¸ªå®˜æ–¹ç»´æŠ¤çš„å…¥é—¨æŒ‡å—ï¼Œå†…å®¹æƒå¨ä¸”æ›´æ–°é¢‘ç¹ï¼Œéå¸¸é€‚åˆåˆå­¦è€…ã€‚"æˆ–"è¯¥é¡¹ç›®æä¾›äº†ä¸€å¥—å®Œæ•´çš„æœ€ä½³å®è·µï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é¿å…å¸¸è§é”™è¯¯ã€‚"ï¼‰
            4.  ä¸€ä¸ªæ€»ç»“æ€§çš„ç»“å°¾ï¼Œé¼“åŠ±ç”¨æˆ·æ¢ç´¢è¿™äº›èµ„æºã€‚

            æŠ¥å‘Šå¿…é¡»ä½¿ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„è¯­è¨€æ’°å†™ï¼Œå¹¶ä»¥ç”¨æˆ·çš„è§†è§’å‡ºå‘ï¼Œé‡ç‚¹çªå‡ºæ¯ä¸ªé¡¹ç›®çš„å®é™…ä»·å€¼ï¼Œè¦ä¸¥æ ¼ç¬¦åˆmarkdownçš„è¯­æ³•ã€‚
            """
            
            # å¡«å……æç¤ºè¯æ¨¡æ¿
            prompt = PromptTemplate.from_template(prompt_template)
            chain = prompt | llm | StrOutputParser()
            
            report = chain.invoke({
                "domain": domain,
                "top_n": min(5, len(repos)),
                "ranked_top_n_repos_details": repos_text
            })
            
            return report
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {e}")
            
            # åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„æŠ¥å‘Šä½œä¸ºåå¤‡
            report = f"# {domain} é¢†åŸŸ GitHub ä¼˜è´¨èµ„æºæ¨è\n\n"
            report += "## ç®€ä»‹\n\n"
            report += f"æœ¬æŠ¥å‘Šä¸ºæ‚¨ç²¾é€‰äº† {domain} é¢†åŸŸä¸­æœ€å…·ä»·å€¼çš„GitHubä»“åº“ï¼ŒåŸºäºStaræ•°é‡ã€Forkæ•°é‡å’Œæ›´æ–°é¢‘ç‡ç­‰å¤šç»´åº¦æŒ‡æ ‡è¿›è¡Œè¯„ä¼°å’Œæ’åºã€‚\n\n"
            
            for i, repo in enumerate(repos[:5], 1):
                pushed_at = repo.get('pushed_at', '')
                if pushed_at:
                    try:
                        date = datetime.strptime(pushed_at, "%Y-%m-%dT%H:%M:%SZ")
                        pushed_at = date.strftime("%Yå¹´%mæœˆ%dæ—¥")
                    except:
                        pass
                        
                report += f"## {i}. {repo.get('full_name', 'Unknown')}\n\n"
                report += f"**é“¾æ¥**: {repo.get('url', '')}\n\n"
                report += f"**æè¿°**: {repo.get('description', '')}\n\n"
                report += f"**æ ¸å¿ƒæŒ‡æ ‡**: â­ {repo.get('stars', 0)} | ğŸ´ {repo.get('forks', 0)} | ğŸ“… {pushed_at}\n\n"
                report += f"**ä¸»è¦è¯­è¨€**: {repo.get('language', 'Unknown')}\n\n"
                report += "---\n\n"
            
            report += "## æ€»ç»“\n\n"
            report += f"ä»¥ä¸Šå°±æ˜¯æˆ‘ä»¬ä¸ºæ‚¨ç²¾é€‰çš„ {domain} é¢†åŸŸä¼˜è´¨GitHubèµ„æºã€‚è¿™äº›é¡¹ç›®ç»è¿‡ç²¾å¿ƒç­›é€‰ï¼Œæ¶µç›–äº†ä»å…¥é—¨åˆ°è¿›é˜¶çš„å¤šç§èµ„æºã€‚å¸Œæœ›è¿™ä»½æ¨èèƒ½å¤Ÿå¸®åŠ©æ‚¨æ›´æ·±å…¥åœ°å­¦ä¹ å’Œæ¢ç´¢æ­¤é¢†åŸŸã€‚\n"
            
            return report 