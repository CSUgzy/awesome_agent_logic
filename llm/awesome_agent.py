import logging
from typing import List, Dict, Tuple, Any
import requests
from bs4 import BeautifulSoup
import json
import concurrent.futures
import re
import math
from datetime import datetime, timedelta
import time

from llm.llm_agent import Agent

class AwesomeAgent:
    """
    AwesomeAgentç±»å®ç°äº†ä¸€ä¸ªå®Œæ•´çš„äº”æ­¥å·¥ä½œæµï¼Œç”¨äºä»GitHubå’Œç½‘ç»œä¸Šæœé›†ã€è¯„ä¼°å’Œæ’åº
    é«˜è´¨é‡çš„èµ„æºåº“ï¼Œå¹¶ç”Ÿæˆä¸€ä»½ç²¾ç‚¼çš„æŠ¥å‘Šã€‚
    
    å·¥ä½œæµç¨‹:
    1. ä»»åŠ¡ç†è§£ä¸å…³é”®è¯ç”Ÿæˆ: åŸºäºç”¨æˆ·è¾“å…¥çš„é¢†åŸŸç”Ÿæˆå¤šæ ·åŒ–çš„æœç´¢å…³é”®è¯
    2. å¹¶è¡Œä¿¡æ¯é‡‡é›†: åŒæ—¶ä»GitHubå’Œç½‘ç»œæ–‡ç« ä¸­æ”¶é›†èµ„æº
    3. ä¿¡æ¯æ¸…æ´—ä¸å€™é€‰æ± æ„å»º: åˆå¹¶å’Œå»é‡æ”¶é›†åˆ°çš„GitHubä»“åº“é“¾æ¥
    4. ç»Ÿä¸€é‡åŒ–è¯„ä¼°ä¸æ’åº: æ ¹æ®Staræ•°ã€Forkæ•°å’Œæ›´æ–°æ—¶é—´ç­‰æŒ‡æ ‡å¯¹ä»“åº“è¿›è¡Œè¯„åˆ†å’Œæ’åº
    5. ç»“æœæç‚¼ä¸æŠ¥å‘Šç”Ÿæˆ: ä¸ºæ’åæœ€é«˜çš„ä»“åº“ç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„MarkdownæŠ¥å‘Š
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–AwesomeAgentå®ä¾‹ã€‚
        è®¾ç½®æ—¥å¿—è®°å½•å™¨å’Œå…¶ä»–å¿…è¦çš„å·¥å…·ã€‚
        """
        self.logger = logging.getLogger(__name__)
        self.logger.setLevel(logging.INFO)
        # ç¡®ä¿æ—¥å¿—æœ‰å¤„ç†å™¨
        if not self.logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
            
        # åˆå§‹åŒ–å·¥å…·é›†
        self.agent = Agent()
            
        self.logger.info("AwesomeAgentåˆå§‹åŒ–å®Œæˆ")
    
    def step_1_generate_keywords(self, domain: str) -> List[str]:
        """
        ç¬¬1æ­¥: ä»»åŠ¡ç†è§£ä¸å…³é”®è¯ç”Ÿæˆ
        
        æ ¹æ®ç”¨æˆ·è¾“å…¥çš„é¢†åŸŸï¼Œç”Ÿæˆä¸€ä¸ªå¤šæ ·åŒ–çš„GitHubæœç´¢å…³é”®è¯åˆ—è¡¨ã€‚
        ä½¿ç”¨LLMæ¥ç¡®ä¿å…³é”®è¯è¦†ç›–ä¸åŒç±»å‹çš„èµ„æº(æ•™ç¨‹ã€æŒ‡å—ã€è·¯çº¿å›¾ç­‰)ã€‚
        
        Args:
            domain (str): ç”¨æˆ·æ„Ÿå…´è¶£çš„é¢†åŸŸï¼Œä¾‹å¦‚"å®¹å™¨åŒ–æŠ€æœ¯"æˆ–"é‡åŒ–é‡‘è"
            
        Returns:
            List[str]: ç”Ÿæˆçš„å…³é”®è¯åˆ—è¡¨ï¼Œä¾‹å¦‚["docker tutorial", "kubernetes guide"]
        """
        self.logger.info(f"å¼€å§‹ä¸ºé¢†åŸŸ '{domain}' ç”Ÿæˆå…³é”®è¯")
        
        try:
            # ç›´æ¥è°ƒç”¨Agentä¸­çš„generate_keywordsæ–¹æ³•ï¼Œå®ƒå·²ç»èƒ½å¤„ç†ä¸­è‹±æ–‡è¾“å…¥å¹¶ç”Ÿæˆè‹±æ–‡å…³é”®è¯
            keywords = self.agent.generate_keywords(domain)
            
            if not keywords:
                self.logger.warning(f"æœªèƒ½ä¸ºé¢†åŸŸ '{domain}' ç”Ÿæˆå…³é”®è¯ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯")
                # å°è¯•ä½¿ç”¨ä¸€äº›é€šç”¨å…³é”®è¯æ¨¡æ¿
                # ç”±äºæˆ‘ä»¬ä¸ç¡®å®šdomainæ˜¯ä»€ä¹ˆè¯­è¨€ï¼Œè¿™é‡Œå¯èƒ½ä¸æ˜¯æœ€ä½³è§£å†³æ–¹æ¡ˆ
                # ä½†ä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼Œç¡®ä¿æµç¨‹å¯ä»¥ç»§ç»­
                keywords = [
                    "tutorial", 
                    "guide", 
                    "awesome repositories", 
                    "best practices", 
                    "examples"
                ]
            
            self.logger.info(f"æˆåŠŸç”Ÿæˆ {len(keywords)} ä¸ªå…³é”®è¯: {keywords}")
            return keywords
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå…³é”®è¯æ—¶å‡ºé”™: {e}")
            # å‡ºé”™æ—¶è¿”å›ä¸€äº›åŸºæœ¬çš„é€šç”¨å…³é”®è¯ï¼Œç¡®ä¿æµç¨‹å¯ä»¥ç»§ç»­
            return ["awesome repositories", "tutorial", "guide", "examples", "resources"]
    
    def step_2_parallel_gather_info(self, keywords: List[str], domain: str) -> Tuple[List[Any], List[str]]:
        """
        ç¬¬2æ­¥: å¹¶è¡Œä¿¡æ¯é‡‡é›†
        
        åŒæ—¶ä»ä¸¤ä¸ªæ¸ é“æ”¶é›†ä¿¡æ¯:
        1. GitHubå†…éƒ¨æœç´¢: ä½¿ç”¨ç”Ÿæˆçš„å…³é”®è¯ç›´æ¥æœç´¢GitHub
        2. äº’è”ç½‘å¤–éƒ¨æœç´¢: æŸ¥æ‰¾æ¨èGitHubä»“åº“çš„é«˜è´¨é‡æ–‡ç« 
        
        Args:
            keywords (List[str]): ç¬¬1æ­¥ç”Ÿæˆçš„å…³é”®è¯åˆ—è¡¨
            domain (str): åŸå§‹é¢†åŸŸåç§°ï¼Œç”¨äºæ„å»ºç½‘ç»œæœç´¢æŸ¥è¯¢
            
        Returns:
            Tuple[List[Any], List[str]]: åŒ…å«ä¸¤éƒ¨åˆ†:
                1. GitHubç›´æ¥æœç´¢ç»“æœåˆ—è¡¨
                2. ç›¸å…³æ–‡ç« URLåˆ—è¡¨
        """
        self.logger.info(f"å¼€å§‹å¹¶è¡Œæ”¶é›†ä¿¡æ¯ï¼Œä½¿ç”¨{len(keywords)}ä¸ªå…³é”®è¯")
        
        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡ŒGitHubæœç´¢å’Œç½‘ç»œæœç´¢
        with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
            # æäº¤GitHubæœç´¢ä»»åŠ¡
            github_future = executor.submit(self._search_github, keywords)
            
            # æäº¤ç½‘ç»œæœç´¢ä»»åŠ¡ - ç›´æ¥ä½¿ç”¨åŸå§‹domainï¼Œgenerate_web_search_queriesæ–¹æ³•ä¼šå¤„ç†è¯­è¨€
            web_future = executor.submit(self._search_web, domain)
            
            # è·å–ç»“æœ
            github_results = github_future.result()
            web_urls = web_future.result()
        
        self.logger.info(f"å¹¶è¡Œæ”¶é›†å®Œæˆ: è·å–äº† {len(github_results)} ä¸ªGitHubä»“åº“å’Œ {len(web_urls)} ä¸ªç½‘é¡µURL")
        return github_results, web_urls
    
    def _search_github(self, keywords: List[str]) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨å…³é”®è¯åœ¨GitHubä¸Šæœç´¢ä»“åº“
        
        Args:
            keywords (List[str]): å…³é”®è¯åˆ—è¡¨
            
        Returns:
            List[Dict[str, Any]]: GitHubä»“åº“åˆ—è¡¨
        """
        self.logger.info(f"å¼€å§‹æœç´¢GitHubï¼Œä½¿ç”¨å…³é”®è¯: {keywords}")
        
        try:
            # è°ƒç”¨Agentä¸­çš„search_github_repositoriesæ–¹æ³•
            repos = self.agent.search_github_repositories(keywords)
            self.logger.info(f"GitHubæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(repos)} ä¸ªä»“åº“")
            return repos
        except Exception as e:
            self.logger.error(f"GitHubæœç´¢å¤±è´¥: {e}")
            return []
    
    def _search_web(self, domain: str) -> List[str]:
        """
        åœ¨ç½‘ç»œä¸Šæœç´¢ä¸é¢†åŸŸç›¸å…³çš„æ–‡ç« ï¼Œè¿™äº›æ–‡ç« å¯èƒ½æ¨èäº†GitHubä»“åº“
        
        Args:
            domain (str): ç”¨æˆ·æ„Ÿå…´è¶£çš„é¢†åŸŸï¼ˆå·²ç¿»è¯‘ä¸ºè‹±æ–‡ï¼‰
            
        Returns:
            List[str]: æ–‡ç« URLåˆ—è¡¨
        """
        self.logger.info(f"å¼€å§‹ç½‘ç»œæœç´¢ï¼Œé¢†åŸŸ: {domain}")
        
        # ç”Ÿæˆé’ˆå¯¹æ€§çš„æœç´¢æŸ¥è¯¢ï¼Œè€Œä¸æ˜¯ç®€å•æ‹¼æ¥
        search_queries = self._generate_web_search_queries(domain)
        
        article_urls = []
        
        try:
            # å°è¯•ä½¿ç”¨tavily APIè¿›è¡Œæœç´¢ï¼ˆå¦‚æœå®‰è£…äº†tavilyï¼‰
            try:
                from tavily import TavilyClient
                from config import Config
                CFG = Config()
                
                if hasattr(CFG, 'tavily_api_key') and CFG.tavily_api_key:
                    self.logger.info("ä½¿ç”¨Tavily APIè¿›è¡Œç½‘ç»œæœç´¢")
                    client = TavilyClient(api_key=CFG.tavily_api_key)
                    
                    for query in search_queries:
                        try:
                            response = client.search(query=query, search_depth="basic", max_results=3)
                            for result in response.get("results", []):
                                if "url" in result and result["url"] not in article_urls:
                                    article_urls.append(result["url"])
                            
                            if len(article_urls) >= 5:
                                break
                        except Exception as e:
                            self.logger.error(f"Tavilyæœç´¢æŸ¥è¯¢ '{query}' å‡ºé”™: {e}")
                    
                    if article_urls:
                        self.logger.info(f"Tavilyæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(article_urls)} ä¸ªæ–‡ç« URL")
                        return article_urls[:5]  # é™åˆ¶æœ€å¤šè¿”å›5ä¸ªURL
            except ImportError:
                self.logger.warning("æœªå®‰è£…tavilyåº“ï¼Œå°†ä½¿ç”¨æ›¿ä»£æœç´¢æ–¹æ³•")
            
            # å¦‚æœtavilyä¸å¯ç”¨æˆ–å¤±è´¥ï¼Œä½¿ç”¨DuckDuckGoæœç´¢
            if not article_urls:
                self.logger.info("ä½¿ç”¨DuckDuckGo APIè¿›è¡Œç½‘ç»œæœç´¢")
                for query in search_queries:
                    try:
                        url = f"https://api.duckduckgo.com/?q={query}&format=json"
                        response = requests.get(url)
                        
                        if response.status_code == 200:
                            # è§£æç»“æœ
                            results = response.json()
                            
                            # æå–æœç´¢ç»“æœä¸­çš„URL
                            for result in results.get("Results", []):
                                if "FirstURL" in result and result["FirstURL"] not in article_urls:
                                    article_urls.append(result["FirstURL"])
                            
                            # é™åˆ¶æ¯ä¸ªæŸ¥è¯¢æœ€å¤š5ä¸ªç»“æœ
                            if len(article_urls) >= 10:
                                break
                        else:
                            self.logger.warning(f"æœç´¢æŸ¥è¯¢ '{query}' è¿”å›çŠ¶æ€ç  {response.status_code}")
                    
                    except Exception as e:
                        self.logger.error(f"æ‰§è¡ŒDuckDuckGoæœç´¢æ—¶å‡ºé”™: {e}")
        
        except Exception as e:
            self.logger.error(f"ç½‘ç»œæœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        
        # å¦‚æœæœç´¢APIéƒ½å¤±è´¥ï¼Œä½¿ç”¨ä¸€äº›å¸¸è§çš„æŠ€æœ¯åšå®¢ä½œä¸ºå¤‡ä»½
        if not article_urls:
            self.logger.warning("ç½‘ç»œæœç´¢æœªè¿”å›ç»“æœï¼Œä½¿ç”¨é»˜è®¤æŠ€æœ¯åšå®¢")
            article_urls = [
                "https://medium.com/topics/programming",
                "https://dev.to/",
                "https://github.blog/",
                "https://www.freecodecamp.org/news/"
            ]
        
        self.logger.info(f"ç½‘ç»œæœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(article_urls)} ä¸ªæ–‡ç« URL")
        return article_urls[:5]  # ç¡®ä¿æœ€å¤šè¿”å›5ä¸ªURL
    
    def _generate_web_search_queries(self, domain: str) -> List[str]:
        """
        ä¸ºç½‘ç»œæœç´¢ç”Ÿæˆä¸“é—¨çš„æŸ¥è¯¢è¯­å¥ï¼Œé¿å…ç®€å•çš„é¢†åŸŸæ‹¼æ¥
        
        Args:
            domain (str): ç”¨æˆ·æ„Ÿå…´è¶£çš„é¢†åŸŸï¼ˆå¯ä»¥æ˜¯ä¸­æ–‡æˆ–è‹±æ–‡ï¼‰
            
        Returns:
            List[str]: ç”Ÿæˆçš„æœç´¢æŸ¥è¯¢åˆ—è¡¨
        """
        self.logger.info(f"ä¸ºé¢†åŸŸ '{domain}' ç”Ÿæˆç½‘ç»œæœç´¢æŸ¥è¯¢")
        
        try:
            # ä½¿ç”¨LLMç”ŸæˆæŸ¥è¯¢
            from langchain_core.prompts import PromptTemplate
            from langchain_core.output_parsers import StrOutputParser
            
            prompt_template = """
            ä½œä¸ºä¸€åæœç´¢ä¸“å®¶ï¼Œä½ çš„ä»»åŠ¡æ˜¯ä¸ºå¯»æ‰¾GitHubä¸Šä¼˜è´¨ä»“åº“èµ„æºç”Ÿæˆæœ‰æ•ˆçš„ç½‘ç»œæœç´¢æŸ¥è¯¢ã€‚
            
            ç”¨æˆ·å¯¹è¿™ä¸ªé¢†åŸŸæ„Ÿå…´è¶£: "{domain}"
            
            è¯·ç”Ÿæˆ3-5ä¸ªä¸åŒçš„æœç´¢æŸ¥è¯¢ï¼Œè¿™äº›æŸ¥è¯¢å¿…é¡»æ˜¯è‹±æ–‡çš„ï¼Œæ— è®ºç”¨æˆ·è¾“å…¥çš„æ˜¯ä»€ä¹ˆè¯­è¨€ã€‚
            è¿™äº›æŸ¥è¯¢åº”è¯¥èƒ½å¸®åŠ©æ‰¾åˆ°æ¨èGitHubä»“åº“çš„é«˜è´¨é‡æ–‡ç« æˆ–èµ„æºåˆ—è¡¨ã€‚
            
            å¦‚æœç”¨æˆ·è¾“å…¥çš„é¢†åŸŸæ˜¯ä¸­æ–‡ï¼Œè¯·å…ˆç†è§£è¯¥é¢†åŸŸçš„å«ä¹‰ï¼Œç„¶åç”Ÿæˆå¯¹åº”çš„è‹±æ–‡æœç´¢æŸ¥è¯¢ã€‚
            
            æŸ¥è¯¢åº”è¯¥å¤šæ ·åŒ–ï¼Œè¦†ç›–ä¸åŒè§’åº¦ï¼Œä¾‹å¦‚ï¼š
            - å¯»æ‰¾"æœ€ä½³/é¡¶çº§/æ¨è"ä»“åº“åˆ—è¡¨
            - å¯»æ‰¾å­¦ä¹ è·¯å¾„æˆ–æ•™ç¨‹é›†åˆ
            - å¯»æ‰¾ä¸“å®¶æ¨èæˆ–ç²¾é€‰èµ„æº
            
            å¯ä»¥ä½¿ç”¨ä¸€äº›ç®€å•çš„æ¨¡æ¿ï¼Œå¦‚"best llm repositories github"ã€‚ä¹Ÿä½¿ç”¨æ›´æœ‰é’ˆå¯¹æ€§çš„æœç´¢è¯­å¥ï¼Œä½†æ˜¯è¯­å¥åº”è¯¥å°½é‡çš„çŸ­ï¼Œæœ€å¥½ä¸è¦è¶…è¿‡5ä¸ªè¯ã€‚
            è€ƒè™‘ç‰¹å®šé¢†åŸŸçš„æœ¯è¯­å’Œå¸¸è§æœç´¢æ¨¡å¼ã€‚
            
            ä½ çš„è¾“å‡ºå¿…é¡»æ˜¯ä¸€ä¸ªJSONæ ¼å¼çš„å­—ç¬¦ä¸²æ•°ç»„ï¼Œä»…åŒ…å«ç”Ÿæˆçš„è‹±æ–‡æŸ¥è¯¢ï¼Œä¸è¦æœ‰é¢å¤–çš„è§£é‡Šã€‚
            
            ç¤ºä¾‹è¾“å‡ºæ ¼å¼:
            ["machine learning github repositories", "top rated deep learning frameworks", "github collections for AI beginners"]
            """
            
            prompt = PromptTemplate.from_template(prompt_template)
            chain = prompt | self.agent.llm | StrOutputParser()
            
            raw_res = chain.invoke({"domain": domain})
            
            # æ¸…ç†å“åº”ï¼Œç¡®ä¿æ˜¯æœ‰æ•ˆçš„JSON
            cleaned_res_str = raw_res.strip()
            if cleaned_res_str.startswith("```json"):
                cleaned_res_str = cleaned_res_str.removeprefix("```json").removesuffix("```")
            elif cleaned_res_str.startswith("```"):
                cleaned_res_str = cleaned_res_str.removeprefix("```").removesuffix("```")
            
            # è§£ææŸ¥è¯¢åˆ—è¡¨
            queries = json.loads(cleaned_res_str)
            
            if not isinstance(queries, list) or not all(isinstance(q, str) for q in queries):
                raise ValueError("Generated queries are not a list of strings.")
                
            self.logger.info(f"æˆåŠŸç”Ÿæˆæœç´¢æŸ¥è¯¢: {queries}")
            return queries
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆæœç´¢æŸ¥è¯¢æ—¶å‡ºé”™: {e}")
            # å‡ºé”™æ—¶è¿”å›ä¸€äº›åŸºæœ¬çš„æŸ¥è¯¢æ¨¡æ¿ï¼Œç¡®ä¿æµç¨‹å¯ä»¥ç»§ç»­
            return [
                "best github repositories",
                "github learning resources",
                "top github projects",
                "recommended github libraries"
            ]
    
    def step_3_build_candidate_pool(self, github_results: List[Any], web_urls: List[str]) -> List[str]:
        """
        ç¬¬3æ­¥: ä¿¡æ¯æ¸…æ´—ä¸å€™é€‰æ± æ„å»º
        
        å¤„ç†ä»ä¸åŒæ¸ é“æ”¶é›†çš„åŸå§‹æ•°æ®:
        1. ä»æ–‡ç« URLä¸­æå–GitHubä»“åº“é“¾æ¥
        2. åˆå¹¶ç›´æ¥æœç´¢ç»“æœå’Œä»æ–‡ç« ä¸­æå–çš„é“¾æ¥
        3. æ‰§è¡Œå»é‡ï¼Œç¡®ä¿æ¯ä¸ªä»“åº“åªå‡ºç°ä¸€æ¬¡
        
        Args:
            github_results (List[Any]): ä»GitHubç›´æ¥æœç´¢å¾—åˆ°çš„ç»“æœ
            web_urls (List[str]): ç›¸å…³æ–‡ç« çš„URLåˆ—è¡¨
            
        Returns:
            List[str]: å»é‡åçš„GitHubä»“åº“URLåˆ—è¡¨
        """
        self.logger.info(f"å¼€å§‹æ„å»ºå€™é€‰æ± ï¼Œå¤„ç†{len(web_urls)}ä¸ªæ–‡ç« URL")
        
        # ç¬¬1æ­¥: ä»GitHubç›´æ¥æœç´¢ç»“æœä¸­æå–URLs
        github_urls = []
        for repo in github_results:
            url = repo.get('html_url')
            if url and self._is_valid_github_repo_url(url):
                github_urls.append(url)
        
        self.logger.info(f"ä»GitHubæœç´¢ç»“æœä¸­æå–äº† {len(github_urls)} ä¸ªæœ‰æ•ˆä»“åº“URL")
        
        # ç¬¬2æ­¥: ä»ç½‘é¡µä¸­æå–GitHubä»“åº“é“¾æ¥
        extracted_urls = []
        
        for url in web_urls:
            try:
                web_repo_urls = self._extract_github_urls_from_webpage(url)
                extracted_urls.extend(web_repo_urls)
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                time.sleep(0.5)
            except Exception as e:
                self.logger.error(f"ä»URL '{url}' æå–GitHubé“¾æ¥æ—¶å‡ºé”™: {e}")
        
        self.logger.info(f"ä»ç½‘é¡µä¸­æå–äº† {len(extracted_urls)} ä¸ªGitHubä»“åº“é“¾æ¥")
        
        # ç¬¬3æ­¥: åˆå¹¶æ‰€æœ‰URLå¹¶å»é‡
        all_urls = github_urls + extracted_urls
        unique_urls = list(set(all_urls))
        
        # ç¬¬4æ­¥: æ ¼å¼åŒ–å’ŒéªŒè¯
        candidate_pool = []
        for url in unique_urls:
            normalized_url = self._normalize_github_url(url)
            if normalized_url and normalized_url not in candidate_pool:
                candidate_pool.append(normalized_url)
        
        self.logger.info(f"æœ€ç»ˆå€™é€‰æ± åŒ…å« {len(candidate_pool)} ä¸ªå”¯ä¸€çš„GitHubä»“åº“")
        return candidate_pool
    
    def _extract_github_urls_from_webpage(self, url: str) -> List[str]:
        """
        ä»ç½‘é¡µå†…å®¹ä¸­æå–GitHubä»“åº“é“¾æ¥ï¼Œæ¯ä¸ªç½‘é¡µæœ€å¤šæå–5ä¸ªé“¾æ¥
        
        Args:
            url (str): è¦æŠ“å–çš„ç½‘é¡µURL
            
        Returns:
            List[str]: æå–çš„GitHubä»“åº“URLåˆ—è¡¨ï¼ˆæœ€å¤š5ä¸ªï¼‰
        """
        github_urls = []
        
        try:
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
            }
            response = requests.get(url, headers=headers, timeout=10)
            
            if response.status_code != 200:
                self.logger.warning(f"è·å– '{url}' å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return []
                
            # è§£æHTML
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # æŸ¥æ‰¾æ‰€æœ‰é“¾æ¥
            for link in soup.find_all('a', href=True):
                href = link['href']
                # æ£€æŸ¥æ˜¯å¦æ˜¯GitHubä»“åº“é“¾æ¥
                if self._is_valid_github_repo_url(href):
                    github_urls.append(href)
                    # è¾¾åˆ°5ä¸ªé“¾æ¥ååœæ­¢æå–
                    if len(github_urls) >= 5:
                        self.logger.info(f"ä»URL '{url}' å·²æå–5ä¸ªGitHubé“¾æ¥ï¼Œåœæ­¢æå–")
                        break
            
            self.logger.info(f"ä»URL '{url}' æå–äº† {len(github_urls)} ä¸ªGitHubé“¾æ¥")
            return github_urls
            
        except Exception as e:
            self.logger.error(f"æŠ“å–URL '{url}' æ—¶å‡ºé”™: {e}")
            return []
    
    def _is_valid_github_repo_url(self, url: str) -> bool:
        """
        æ£€æŸ¥URLæ˜¯å¦æ˜¯æœ‰æ•ˆçš„GitHubä»“åº“é“¾æ¥
        
        Args:
            url (str): è¦æ£€æŸ¥çš„URL
            
        Returns:
            bool: æ˜¯å¦æ˜¯æœ‰æ•ˆçš„GitHubä»“åº“URL
        """
        # ç®€å•çš„æ­£åˆ™è¡¨è¾¾å¼æ£€æŸ¥
        pattern = r'https?://github\.com/[a-zA-Z0-9\-]+/[a-zA-Z0-9\-\._]+/?$'
        return bool(re.match(pattern, url))
    
    def _normalize_github_url(self, url: str) -> str:
        """
        è§„èŒƒåŒ–GitHub URLï¼Œç§»é™¤å°¾éƒ¨æ–œæ å’Œä¸å¿…è¦çš„å‚æ•°
        
        Args:
            url (str): åŸå§‹GitHub URL
            
        Returns:
            str: è§„èŒƒåŒ–åçš„URLï¼Œæˆ–è€…ç©ºå­—ç¬¦ä¸²(å¦‚æœæ— æ•ˆ)
        """
        # æ£€æŸ¥åŸºæœ¬æ¨¡å¼
        basic_pattern = r'https?://github\.com/[a-zA-Z0-9\-]+/[a-zA-Z0-9\-\._]+'
        if not re.match(basic_pattern, url):
            return ""
            
        # ç§»é™¤URLå‚æ•°å’Œé”šç‚¹
        clean_url = re.sub(r'[#?].*$', '', url)
        
        # ç§»é™¤å°¾éƒ¨æ–œæ 
        clean_url = clean_url.rstrip('/')
        
        return clean_url
    
    def step_4_evaluate_and_rank(self, candidate_pool: List[str]) -> List[Dict]:
        """
        ç¬¬4æ­¥: ç»Ÿä¸€é‡åŒ–è¯„ä¼°ä¸æ’åº
        
        å¯¹å€™é€‰æ± ä¸­çš„æ¯ä¸ªä»“åº“è¿›è¡Œé‡åŒ–è¯„ä¼°:
        1. è·å–æ¯ä¸ªä»“åº“çš„è¯¦ç»†å…ƒæ•°æ®(Staræ•°ã€Forkæ•°ã€æœ€è¿‘æ›´æ–°æ—¥æœŸ)
        2. åº”ç”¨è¯„åˆ†å…¬å¼è®¡ç®—ç»¼åˆåˆ†æ•°
        3. æ ¹æ®åˆ†æ•°å¯¹ä»“åº“è¿›è¡Œæ’åº
        
        è¯„åˆ†å…¬å¼: (0.7 * log(Stars + 1) + 0.3 * log(Forks + 1)) * RecencyScore
        
        Args:
            candidate_pool (List[str]): å€™é€‰GitHubä»“åº“URLåˆ—è¡¨
            
        Returns:
            List[Dict]: åŒ…å«æ’åºåçš„ä»“åº“è¯¦æƒ…çš„å­—å…¸åˆ—è¡¨ï¼Œæ¯ä¸ªå­—å…¸åŒ…å«:
                - url: ä»“åº“URL
                - name: ä»“åº“åç§°
                - description: ä»“åº“æè¿°
                - stars: Staræ•°é‡
                - forks: Forkæ•°é‡
                - pushed_at: æœ€è¿‘æ›´æ–°æ—¶é—´
                - score: è®¡ç®—çš„ç»¼åˆåˆ†æ•°
        """
        self.logger.info(f"å¼€å§‹è¯„ä¼°å’Œæ’åº{len(candidate_pool)}ä¸ªå€™é€‰ä»“åº“")
        
        # è·å–æ¯ä¸ªä»“åº“çš„è¯¦ç»†ä¿¡æ¯
        repos_with_metadata = []
        
        for url in candidate_pool:
            try:
                # ä»URLä¸­æå–ç”¨æˆ·å’Œä»“åº“å
                parts = url.split('/')
                if len(parts) >= 5:
                    owner = parts[-2]
                    repo_name = parts[-1]
                    
                    # è·å–ä»“åº“è¯¦ç»†ä¿¡æ¯
                    repo_data = self._get_github_repo_metadata(owner, repo_name)
                    
                    if repo_data:
                        repos_with_metadata.append(repo_data)
                else:
                    self.logger.warning(f"æ— æ³•ä»URL '{url}' è§£æå‡ºæ‰€æœ‰è€…å’Œä»“åº“å")
            
            except Exception as e:
                self.logger.error(f"è·å–ä»“åº“ '{url}' çš„å…ƒæ•°æ®æ—¶å‡ºé”™: {e}")
            
            # é¿å…APIé™é€Ÿ
            time.sleep(0.5)
        
        self.logger.info(f"æˆåŠŸè·å– {len(repos_with_metadata)} ä¸ªä»“åº“çš„å…ƒæ•°æ®")
        
        # è®¡ç®—æ¯ä¸ªä»“åº“çš„åˆ†æ•°
        ranked_repos = []
        for repo in repos_with_metadata:
            if 'stargazers_count' in repo and 'forks_count' in repo and 'pushed_at' in repo:
                # è®¡ç®—æ–°è¿‘åº¦åˆ†æ•°
                recency_score = self._calculate_recency_score(repo['pushed_at'])
                
                # è®¡ç®—ç»¼åˆåˆ†æ•°
                comprehensive_score = (
                    0.7 * math.log(repo['stargazers_count'] + 1) + 
                    0.3 * math.log(repo['forks_count'] + 1)
                ) * recency_score
                
                # æ·»åŠ åˆ†æ•°åˆ°ä»“åº“æ•°æ®
                repo['score'] = comprehensive_score
                ranked_repos.append(repo)
            else:
                self.logger.warning(f"ä»“åº“ '{repo.get('full_name', 'unknown')}' ç¼ºå°‘è¯„åˆ†æ‰€éœ€çš„å­—æ®µ")
        
        # æŒ‰åˆ†æ•°é™åºæ’åº
        ranked_repos.sort(key=lambda x: x['score'], reverse=True)
        
        self.logger.info(f"è¯„ä¼°å’Œæ’åºå®Œæˆï¼Œè¿”å› {len(ranked_repos)} ä¸ªæ’åºåçš„ä»“åº“")
        return ranked_repos
    
    def _get_github_repo_metadata(self, owner: str, repo: str) -> Dict[str, Any]:
        """
        ä»GitHub APIè·å–ä»“åº“çš„è¯¦ç»†å…ƒæ•°æ®
        
        Args:
            owner (str): ä»“åº“æ‰€æœ‰è€…
            repo (str): ä»“åº“åç§°
            
        Returns:
            Dict[str, Any]: ä»“åº“å…ƒæ•°æ®ï¼ŒåŒ…å«name, description, stars, forks, pushed_atç­‰
        """
        from config import Config
        CFG = Config()
        
        url = f"https://api.github.com/repos/{owner}/{repo}"
        headers = {
            'Authorization': f'token {CFG.github_access_token}',
            'Accept': 'application/vnd.github+json',
            'X-GitHub-Api-Version': '2022-11-28'
        }
        
        try:
            response = requests.get(url, headers=headers)
            response.raise_for_status()
            
            data = response.json()
            return {
                'url': data['html_url'],
                'name': data['name'],
                'full_name': data['full_name'],
                'description': data.get('description', ''),
                'stargazers_count': data['stargazers_count'],
                'forks_count': data['forks_count'],
                'pushed_at': data['pushed_at'],
                'created_at': data['created_at'],
                'updated_at': data['updated_at'],
                'language': data.get('language')
            }
            
        except Exception as e:
            self.logger.error(f"è·å–ä»“åº“ '{owner}/{repo}' çš„å…ƒæ•°æ®å¤±è´¥: {e}")
            return {}
    
    def _calculate_recency_score(self, pushed_at_str: str) -> float:
        """
        æ ¹æ®æœ€è¿‘æ¨é€æ—¥æœŸè®¡ç®—æ–°è¿‘åº¦åˆ†æ•°
        
        æ–°è¿‘åº¦è¯„åˆ†:
        - 1ä¸ªæœˆå†…æ›´æ–°: 1.0
        - 6ä¸ªæœˆå†…æ›´æ–°: 0.8
        - 1å¹´å†…æ›´æ–°: 0.5
        - 2å¹´å†…æ›´æ–°: 0.2
        - è¶…è¿‡2å¹´æœªæ›´æ–°: 0.05
        
        Args:
            pushed_at_str (str): æœ€è¿‘æ¨é€æ—¥æœŸå­—ç¬¦ä¸²ï¼ŒISO 8601æ ¼å¼
            
        Returns:
            float: æ–°è¿‘åº¦åˆ†æ•° (0.05-1.0)
        """
        try:
            # è§£ææ—¥æœŸ
            pushed_at = datetime.strptime(pushed_at_str, "%Y-%m-%dT%H:%M:%SZ")
            now = datetime.utcnow()
            
            # è®¡ç®—å¤©æ•°å·®å¼‚
            days_diff = (now - pushed_at).days
            
            # è¯„åˆ†é€»è¾‘
            if days_diff <= 30:  # 1ä¸ªæœˆå†…
                return 1.0
            elif days_diff <= 180:  # 6ä¸ªæœˆå†…
                return 0.8
            elif days_diff <= 365:  # 1å¹´å†…
                return 0.5
            elif days_diff <= 730:  # 2å¹´å†…
                return 0.2
            else:  # è¶…è¿‡2å¹´
                return 0.05
                
        except Exception as e:
            self.logger.error(f"è®¡ç®—æ–°è¿‘åº¦åˆ†æ•°æ—¶å‡ºé”™: {e}")
            return 0.1  # å‡ºé”™æ—¶è¿”å›ä¸€ä¸ªä½åˆ†
    
    def step_5_generate_report(self, ranked_repos: List[Dict], domain: str) -> str:
        """
        ç¬¬5æ­¥: ç»“æœæç‚¼ä¸æŠ¥å‘Šç”Ÿæˆ
        
        é€‰å–æ’åæœ€é«˜çš„ä»“åº“ï¼Œå¹¶ç”Ÿæˆä¸€ä»½é«˜è´¨é‡çš„Markdownæ ¼å¼æŠ¥å‘Š:
        1. é€‰æ‹©æ’åæœ€é«˜çš„Nä¸ªä»“åº“(é»˜è®¤ä¸º5ä¸ª)
        2. ä½¿ç”¨LLMç”Ÿæˆä¸€ä»½ç»“æ„åŒ–çš„æŠ¥å‘Šï¼Œå¼ºè°ƒæ¯ä¸ªä»“åº“çš„ä»·å€¼å’Œç‰¹ç‚¹
        
        Args:
            ranked_repos (List[Dict]): æ’åºåçš„ä»“åº“è¯¦æƒ…åˆ—è¡¨
            domain (str): ç”¨æˆ·åŸå§‹æŸ¥è¯¢çš„é¢†åŸŸ
            
        Returns:
            str: Markdownæ ¼å¼çš„æœ€ç»ˆæŠ¥å‘Š
        """
        self.logger.info("å¼€å§‹ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š")
        
        # é€‰å–æ’åæœ€é«˜çš„ä»“åº“ï¼ˆé»˜è®¤5ä¸ªï¼Œå¦‚æœä¸è¶³åˆ™å…¨éƒ¨é€‰å–ï¼‰
        top_n = 5
        top_repos = ranked_repos[:min(top_n, len(ranked_repos))]
        
        if not top_repos:
            self.logger.warning("æ²¡æœ‰å¯ç”¨çš„ä»“åº“æ¥ç”ŸæˆæŠ¥å‘Š")
            return f"# {domain} é¢†åŸŸGitHubèµ„æºæ¨è\n\nå¾ˆé—æ†¾ï¼Œæˆ‘ä»¬æœªèƒ½æ‰¾åˆ°ç¬¦åˆè¦æ±‚çš„é«˜è´¨é‡GitHubä»“åº“ã€‚è¯·å°è¯•ä½¿ç”¨å…¶ä»–å…³é”®è¯æˆ–é¢†åŸŸã€‚"
        
        self.logger.info(f"ä¸ºæŠ¥å‘Šé€‰æ‹©äº†æ’åæœ€é«˜çš„ {len(top_repos)} ä¸ªä»“åº“")
        
        # æ ¼å¼åŒ–ä»“åº“ä¿¡æ¯ï¼Œå‡†å¤‡ä¼ é€’ç»™LLM
        repos_details = []
        for repo in top_repos:
            # æ ¼å¼åŒ–æ—¥æœŸ
            pushed_at = self._format_date(repo.get('pushed_at', ''))
            
            # åˆ›å»ºè¯¦ç»†ä¿¡æ¯
            repo_detail = {
                "name": repo.get('name', 'Unknown'),
                "full_name": repo.get('full_name', 'Unknown'),
                "url": repo.get('url', ''),
                "description": repo.get('description', 'No description available'),
                "stars": repo.get('stargazers_count', 0),
                "forks": repo.get('forks_count', 0),
                "pushed_at": pushed_at,
                "language": repo.get('language', 'Unknown')
            }
            repos_details.append(repo_detail)
        
        # å‡†å¤‡LLMæç¤ºè¯
        report_prompt = self._create_report_prompt(domain, repos_details)
        
        try:
            # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š
            final_report = self._generate_report_with_llm(report_prompt)
            self.logger.info("æœ€ç»ˆæŠ¥å‘Šç”ŸæˆæˆåŠŸ")
            return final_report
        except Exception as e:
            self.logger.error(f"ç”ŸæˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
            # å¦‚æœLLMè°ƒç”¨å¤±è´¥ï¼Œç”Ÿæˆä¸€ä¸ªåŸºæœ¬çš„æŠ¥å‘Š
            return self._create_basic_report(domain, repos_details)
    
    def _format_date(self, date_str: str) -> str:
        """æ ¼å¼åŒ–ISO 8601æ—¥æœŸå­—ç¬¦ä¸²ä¸ºæ›´å‹å¥½çš„æ ¼å¼"""
        if not date_str:
            return "æœªçŸ¥æ—¥æœŸ"
        
        try:
            date = datetime.strptime(date_str, "%Y-%m-%dT%H:%M:%SZ")
            return date.strftime("%Yå¹´%mæœˆ%dæ—¥")
        except Exception:
            return date_str
    
    def _create_report_prompt(self, domain: str, repos_details: List[Dict]) -> str:
        """
        åˆ›å»ºç”¨äºç”ŸæˆæŠ¥å‘Šçš„LLMæç¤ºè¯
        
        Args:
            domain (str): ç”¨æˆ·æŸ¥è¯¢çš„é¢†åŸŸ
            repos_details (List[Dict]): æ’åæœ€é«˜çš„ä»“åº“è¯¦ç»†ä¿¡æ¯
            
        Returns:
            str: æ ¼å¼åŒ–çš„æç¤ºè¯
        """
        # è½¬æ¢ä»“åº“è¯¦æƒ…ä¸ºæ ¼å¼åŒ–æ–‡æœ¬
        repos_text = ""
        for i, repo in enumerate(repos_details, 1):
            repos_text += f"## ä»“åº“ {i}\n"
            repos_text += f"åç§°: {repo['full_name']}\n"
            repos_text += f"URL: {repo['url']}\n"
            repos_text += f"æè¿°: {repo['description']}\n"
            repos_text += f"Stars: {repo['stars']}\n"
            repos_text += f"Forks: {repo['forks']}\n"
            repos_text += f"æœ€è¿‘æ›´æ–°: {repo['pushed_at']}\n"
            repos_text += f"ä¸»è¦è¯­è¨€: {repo['language']}\n\n"
        
        # ä½¿ç”¨prompt.mdä¸­ä¸ºç¬¬5æ­¥è®¾è®¡çš„æç¤ºè¯æ¨¡æ¿
        prompt_template = """
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„AIæŠ€æœ¯åˆ†æå¸ˆã€‚ä½ çš„ä»»åŠ¡æ˜¯ä¸ºç”¨æˆ·å‡†å¤‡ä¸€ä»½å…³äº"{domain}"é¢†åŸŸçš„é¡¶å°– GitHub å­¦ä¹ èµ„æºæŠ¥å‘Šã€‚

æˆ‘å·²ç»ä¸ºä½ æä¾›äº†æ’åæœ€é«˜çš„ {top_n} ä¸ªä»“åº“çš„è¯¦ç»†ä¿¡æ¯ï¼ˆåç§°ã€URLã€æè¿°ã€Staræ•°ã€Forkæ•°ã€æœ€è¿‘æ›´æ–°æ—¶é—´ï¼‰ã€‚

**ä»“åº“ä¿¡æ¯**:
{ranked_top_n_repos_details}

è¯·æ ¹æ®ä»¥ä¸Šä¿¡æ¯ï¼Œç”Ÿæˆä¸€ä»½ç²¾ç‚¼ã€æ˜“è¯»çš„ Markdown æ ¼å¼æŠ¥å‘Šï¼Œè¦ä¸¥æ ¼ç¬¦åˆmarkdownçš„è¯­æ³•ã€‚æŠ¥å‘Šåº”åŒ…å«ä»¥ä¸‹è¦ç´ ï¼š

1.  ä¸€ä¸ªå¼•äººæ³¨ç›®çš„æ ‡é¢˜ï¼Œç‚¹æ˜æŠ¥å‘Šä¸»é¢˜ï¼ˆä¾‹å¦‚ï¼š" Top 5 GitHub å®è—é¡¹ç›®æ¨èï¼‰ã€‚
2.  ä¸€æ®µç®€çŸ­çš„å¼•è¨€ï¼Œè¯´æ˜è¿™ä»½æŠ¥å‘Šæ˜¯å¦‚ä½•é€šè¿‡å¤šç»´åº¦è¯„ä¼°å¾—å‡ºçš„ï¼Œå¼ºè°ƒå…¶å®¢è§‚æ€§å’Œæ—¶æ•ˆæ€§ã€‚
3.  å¯¹æ¯ä¸€ä¸ªæ¨èä»“åº“çš„ç‹¬ç«‹ä»‹ç»ï¼ŒåŒ…æ‹¬ï¼š
    - **é¡¹ç›®åç§°å’Œé“¾æ¥**: ä½œä¸ºäºŒçº§æˆ–ä¸‰çº§æ ‡é¢˜ã€‚
    - **æ ¸å¿ƒæŒ‡æ ‡**: `Stars`, `Forks`, `æœ€è¿‘æ›´æ–°`ã€‚
    - **ä¸€å¥è¯æ€»ç»“**: ç²¾å‡†æ¦‚æ‹¬è¿™ä¸ªé¡¹ç›®æ˜¯ä»€ä¹ˆã€‚
    - **æ¨èç†ç”±**: è¯¦ç»†è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªé¡¹ç›®å€¼å¾—å…³æ³¨ã€‚å®ƒè§£å†³äº†ä»€ä¹ˆé—®é¢˜ï¼Ÿæ˜¯æ•™ç¨‹ã€å·¥å…·è¿˜æ˜¯èµ„æºåº“ï¼Ÿï¼ˆä¾‹å¦‚ï¼š"è¿™æ˜¯ä¸€ä¸ªå®˜æ–¹ç»´æŠ¤çš„å…¥é—¨æŒ‡å—ï¼Œå†…å®¹æƒå¨ä¸”æ›´æ–°é¢‘ç¹ï¼Œéå¸¸é€‚åˆåˆå­¦è€…ã€‚"æˆ–"è¯¥é¡¹ç›®æä¾›äº†ä¸€å¥—å®Œæ•´çš„æœ€ä½³å®è·µï¼Œå¯ä»¥å¸®åŠ©å¼€å‘è€…åœ¨ç”Ÿäº§ç¯å¢ƒä¸­é¿å…å¸¸è§é”™è¯¯ã€‚"ï¼‰
4.  ä¸€ä¸ªæ€»ç»“æ€§çš„ç»“å°¾ï¼Œé¼“åŠ±ç”¨æˆ·æ¢ç´¢è¿™äº›èµ„æºã€‚

æŠ¥å‘Šå¿…é¡»ä½¿ç”¨æ¸…æ™°ã€ä¸“ä¸šçš„è¯­è¨€æ’°å†™ï¼Œå¹¶ä»¥ç”¨æˆ·çš„è§†è§’å‡ºå‘ï¼Œé‡ç‚¹çªå‡ºæ¯ä¸ªé¡¹ç›®çš„å®é™…ä»·å€¼ï¼Œè¦ä¸¥æ ¼ç¬¦åˆmarkdownçš„è¯­æ³•ã€‚
        """
        
        # å¡«å……æç¤ºè¯æ¨¡æ¿
        prompt = prompt_template.replace("{domain}", domain)
        prompt = prompt.replace("{top_n}", str(len(repos_details)))
        prompt = prompt.replace("{ranked_top_n_repos_details}", repos_text)
        
        return prompt
    
    def _generate_report_with_llm(self, prompt: str) -> str:
        """
        ä½¿ç”¨LLMç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        
        Args:
            prompt (str): æç¤ºè¯
            
        Returns:
            str: ç”Ÿæˆçš„MarkdownæŠ¥å‘Š
        """
        from langchain_core.prompts import PromptTemplate
        from langchain_core.output_parsers import StrOutputParser
        
        # åˆ›å»ºæç¤ºè¯æ¨¡æ¿
        prompt_template = PromptTemplate.from_template("{prompt}")
        
        # è®¾ç½®è¾“å‡ºè§£æå™¨
        output_parser = StrOutputParser()
        
        # åˆ›å»ºé“¾
        chain = prompt_template | self.agent.llm | output_parser
        
        # è°ƒç”¨LLM
        report = chain.invoke({"prompt": prompt})
        
        return report
    
    def _create_basic_report(self, domain: str, repos_details: List[Dict]) -> str:
        """
        åœ¨LLMè°ƒç”¨å¤±è´¥æ—¶åˆ›å»ºä¸€ä¸ªåŸºæœ¬çš„æŠ¥å‘Š
        
        Args:
            domain (str): ç”¨æˆ·æŸ¥è¯¢çš„é¢†åŸŸ
            repos_details (List[Dict]): ä»“åº“è¯¦ç»†ä¿¡æ¯
            
        Returns:
            str: åŸºæœ¬çš„MarkdownæŠ¥å‘Š
        """
        report = f"# {domain} é¢†åŸŸ GitHub ä¼˜è´¨èµ„æºæ¨è\n\n"
        
        report += "## ç®€ä»‹\n\n"
        report += f"æœ¬æŠ¥å‘Šä¸ºæ‚¨ç²¾é€‰äº† {domain} é¢†åŸŸä¸­æœ€å…·ä»·å€¼çš„GitHubä»“åº“ï¼ŒåŸºäºStaræ•°é‡ã€Forkæ•°é‡å’Œæ›´æ–°é¢‘ç‡ç­‰å¤šç»´åº¦æŒ‡æ ‡è¿›è¡Œè¯„ä¼°å’Œæ’åºã€‚\n\n"
        
        for i, repo in enumerate(repos_details, 1):
            report += f"## {i}. {repo['full_name']}\n\n"
            report += f"**é“¾æ¥**: {repo['url']}\n\n"
            report += f"**æè¿°**: {repo['description']}\n\n"
            report += f"**æ ¸å¿ƒæŒ‡æ ‡**: â­ {repo['stars']} | ğŸ´ {repo['forks']} | ğŸ“… {repo['pushed_at']}\n\n"
            report += f"**ä¸»è¦è¯­è¨€**: {repo['language']}\n\n"
            report += "---\n\n"
        
        report += "## æ€»ç»“\n\n"
        report += f"ä»¥ä¸Šå°±æ˜¯æˆ‘ä»¬ä¸ºæ‚¨ç²¾é€‰çš„ {domain} é¢†åŸŸä¼˜è´¨GitHubèµ„æºã€‚è¿™äº›é¡¹ç›®ç»è¿‡ç²¾å¿ƒç­›é€‰ï¼Œæ¶µç›–äº†ä»å…¥é—¨åˆ°è¿›é˜¶çš„å¤šç§èµ„æºã€‚å¸Œæœ›è¿™ä»½æ¨èèƒ½å¤Ÿå¸®åŠ©æ‚¨æ›´æ·±å…¥åœ°å­¦ä¹ å’Œæ¢ç´¢æ­¤é¢†åŸŸã€‚\n"
        
        return report
    
    def run(self, domain: str) -> str:
        """
        æ‰§è¡Œå®Œæ•´çš„äº”æ­¥å·¥ä½œæµã€‚
        
        è¿™æ˜¯ç”¨æˆ·äº¤äº’çš„ä¸»è¦å…¥å£ç‚¹ã€‚æ¥æ”¶ä¸€ä¸ªé¢†åŸŸï¼ŒæŒ‰é¡ºåºæ‰§è¡Œæ‰€æœ‰äº”ä¸ªæ­¥éª¤ï¼Œ
        æ¯ä¸€æ­¥çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€æ­¥çš„è¾“å…¥ï¼Œæœ€ç»ˆè¿”å›ç”Ÿæˆçš„æŠ¥å‘Šã€‚
        
        Args:
            domain (str): ç”¨æˆ·æ„Ÿå…´è¶£çš„é¢†åŸŸ
            
        Returns:
            str: æœ€ç»ˆç”Ÿæˆçš„Markdownæ ¼å¼æŠ¥å‘Š
        """
        self.logger.info(f"å¼€å§‹ä¸ºé¢†åŸŸ '{domain}' æ‰§è¡Œå®Œæ•´çš„Awesome Agentå·¥ä½œæµ")
        
        # æ‰§è¡Œç¬¬1æ­¥: ä»»åŠ¡ç†è§£ä¸å…³é”®è¯ç”Ÿæˆ
        keywords = self.step_1_generate_keywords(domain)
        self.logger.info(f"ç¬¬1æ­¥å®Œæˆï¼Œç”Ÿæˆäº†{len(keywords)}ä¸ªå…³é”®è¯")
        
        # æ‰§è¡Œç¬¬2æ­¥: å¹¶è¡Œä¿¡æ¯é‡‡é›†
        github_results, web_urls = self.step_2_parallel_gather_info(keywords, domain)
        self.logger.info(f"ç¬¬2æ­¥å®Œæˆï¼Œè·å–äº†{len(github_results)}ä¸ªGitHubç»“æœå’Œ{len(web_urls)}ä¸ªç½‘é¡µURL")
        
        # æ‰§è¡Œç¬¬3æ­¥: ä¿¡æ¯æ¸…æ´—ä¸å€™é€‰æ± æ„å»º
        candidate_pool = self.step_3_build_candidate_pool(github_results, web_urls)
        self.logger.info(f"ç¬¬3æ­¥å®Œæˆï¼Œæ„å»ºäº†åŒ…å«{len(candidate_pool)}ä¸ªä»“åº“çš„å€™é€‰æ± ")
        
        # æ‰§è¡Œç¬¬4æ­¥: ç»Ÿä¸€é‡åŒ–è¯„ä¼°ä¸æ’åº
        ranked_repos = self.step_4_evaluate_and_rank(candidate_pool)
        self.logger.info(f"ç¬¬4æ­¥å®Œæˆï¼Œè¯„ä¼°å¹¶æ’åºäº†{len(ranked_repos)}ä¸ªä»“åº“")
        
        # æ‰§è¡Œç¬¬5æ­¥: ç»“æœæç‚¼ä¸æŠ¥å‘Šç”Ÿæˆ
        final_report = self.step_5_generate_report(ranked_repos, domain)
        self.logger.info("ç¬¬5æ­¥å®Œæˆï¼Œç”Ÿæˆäº†æœ€ç»ˆæŠ¥å‘Š")
        
        return final_report 